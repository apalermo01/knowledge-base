{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79ee3d3d",
   "metadata": {},
   "source": [
    "# Preprocessing with a tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13b689e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34ca64da",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82410f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertTokenizerFast(name_or_path='distilbert-base-uncased-finetuned-sst-2-english', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cf0da72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n",
       "          2607,  2026,  2878,  2166,  1012,   102],\n",
       "        [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_inputs = [\n",
    "    \"I've been waiting for a huggingface course my whole life.\",\n",
    "    \"I hate this so much!\"\n",
    "]\n",
    "\n",
    "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112a5306",
   "metadata": {},
   "source": [
    "These tokens are the unique tokens ids for each word in the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f62b9d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english were not used when initializing DistilBertModel: ['classifier.weight', 'pre_classifier.weight', 'pre_classifier.bias', 'classifier.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "model = AutoModel.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dfa8594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.distilbert.modeling_distilbert.DistilBertModel"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea5eddf",
   "metadata": {},
   "source": [
    "The inputs to a model usually has 3 dimensions: [batch_size, sequence_length, hidden size]\n",
    "\n",
    "batch size = number of sequences processed at a time\n",
    "\n",
    "sequence length = length of the numerical representation of the sequence\n",
    "\n",
    "hidden size = the vector dimension of each model input\n",
    "\n",
    "hidden size can be very large (768 for small er models, 3072 or more in larger models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "243469e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutput(last_hidden_state=tensor([[[-0.1798,  0.2333,  0.6321,  ..., -0.3017,  0.5008,  0.1481],\n",
      "         [ 0.2758,  0.6497,  0.3200,  ..., -0.0760,  0.5136,  0.1329],\n",
      "         [ 0.9046,  0.0985,  0.2950,  ...,  0.3352, -0.1407, -0.6464],\n",
      "         ...,\n",
      "         [ 0.1466,  0.5661,  0.3235,  ..., -0.3376,  0.5100, -0.0561],\n",
      "         [ 0.7500,  0.0487,  0.1738,  ...,  0.4684,  0.0030, -0.6084],\n",
      "         [ 0.0519,  0.3729,  0.5223,  ...,  0.3584,  0.6500, -0.3883]],\n",
      "\n",
      "        [[-0.2937,  0.7283, -0.1497,  ..., -0.1187, -1.0227, -0.0422],\n",
      "         [-0.2206,  0.9384, -0.0951,  ..., -0.3643, -0.6605,  0.2407],\n",
      "         [-0.1536,  0.8988, -0.0728,  ..., -0.2189, -0.8528,  0.0710],\n",
      "         ...,\n",
      "         [-0.3017,  0.9002, -0.0200,  ..., -0.1082, -0.8412, -0.0861],\n",
      "         [-0.3338,  0.9674, -0.0729,  ..., -0.1952, -0.8181, -0.0634],\n",
      "         [-0.3454,  0.8824, -0.0426,  ..., -0.0993, -0.8329, -0.1065]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), hidden_states=None, attentions=None)\n",
      "torch.Size([2, 16, 768])\n"
     ]
    }
   ],
   "source": [
    "outputs = model(**inputs)\n",
    "print(outputs)\n",
    "print(outputs.last_hidden_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f50d02d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(512, 768)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embeddings.position_embeddings"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "44ad8c60",
   "metadata": {},
   "source": [
    "Outputs of models behaved like namedtuples / dictionaries.\n",
    "\n",
    "The model heads take high-dimensional vector hof hidden states and transform them into a different dimension. Outputs of the transformer is sent to the head to be processed. \n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406ed666",
   "metadata": {},
   "source": [
    "Embeddings: convert each input id in the tokenized input into a vector that represents the associated token. Subsequent layers manipulate those vectors using the attention mechanism to produce a final representation of the sentences.\n",
    "\n",
    "Each architecture is designed aroudn tackling a specific task:\n",
    "\n",
    "- Model (retrieves hidden states)\n",
    "- ForCausalLM\n",
    "- ForMaskedLM\n",
    "- ForSequenceClassification\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1865c0",
   "metadata": {},
   "source": [
    "In this case (sentiment analysis), we'll need a model with a sequence classification head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3cfd492",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2707296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b672fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(outputs.logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4fd57c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-1.5607,  1.6123],\n",
       "        [ 4.1692, -3.3464]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9041508",
   "metadata": {},
   "source": [
    "## Postprocessing the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a690f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.0195e-02, 9.5980e-01],\n",
      "        [9.9946e-01, 5.4418e-04]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd9c906",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a5b86f",
   "metadata": {},
   "source": [
    "- the AutoModel class lets you initialize any model from a checkpoint\n",
    "- It's a wrapper that wraps over all the models in the hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa6068ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.30.2\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize a BERT model using a load configuration object\n",
    "from transformers import BertConfig, BertModel\n",
    "\n",
    "config = BertConfig()\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95aee8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertModel(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3eac27",
   "metadata": {},
   "source": [
    "Right now, the model has been randomly initialized (not trained!)\n",
    "\n",
    "Ideally, we'd like to stick to using pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c5004cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f82638db81540c6b0a7d919361f5c17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44f2222620ea48e3ba3abe9a7d78ea27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = BertModel.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4558df7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets say we have some sequences:\n",
    "sequences = [\"Hello!\", \"Cool.\", \"Nice!\"]\n",
    "\n",
    "# the tokenizer converts these to vocabulary indices which are called input ids.\n",
    "# the resulting output of the tokenizer is:\n",
    "\n",
    "encoded_sequences = [\n",
    "    [101, 7592, 999, 102],\n",
    "    [101, 4658, 1012, 102],\n",
    "    [101, 3835, 999, 102]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83929b1c",
   "metadata": {},
   "source": [
    "And now we can convert this to a tensor and use it in the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e76caa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "model_inputs = torch.tensor(encoded_sequences)\n",
    "output = model(model_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b065d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 4.4496e-01,  4.8276e-01,  2.7797e-01,  ..., -5.4032e-02,\n",
       "           3.9394e-01, -9.4770e-02],\n",
       "         [ 2.4943e-01, -4.4093e-01,  8.1772e-01,  ..., -3.1917e-01,\n",
       "           2.2992e-01, -4.1172e-02],\n",
       "         [ 1.3668e-01,  2.2518e-01,  1.4502e-01,  ..., -4.6915e-02,\n",
       "           2.8224e-01,  7.5566e-02],\n",
       "         [ 1.1789e+00,  1.6738e-01, -1.8187e-01,  ...,  2.4671e-01,\n",
       "           1.0441e+00, -6.1963e-03]],\n",
       "\n",
       "        [[ 3.6436e-01,  3.2465e-02,  2.0258e-01,  ...,  6.0111e-02,\n",
       "           3.2451e-01, -2.0996e-02],\n",
       "         [ 7.1866e-01, -4.8725e-01,  5.1740e-01,  ..., -4.4012e-01,\n",
       "           1.4553e-01, -3.7545e-02],\n",
       "         [ 3.3223e-01, -2.3271e-01,  9.4876e-02,  ..., -2.5268e-01,\n",
       "           3.2172e-01,  8.1106e-04],\n",
       "         [ 1.2523e+00,  3.5754e-01, -5.1321e-02,  ..., -3.7840e-01,\n",
       "           1.0526e+00, -5.6255e-01]],\n",
       "\n",
       "        [[ 2.4042e-01,  1.4718e-01,  1.2110e-01,  ...,  7.6061e-02,\n",
       "           3.3564e-01,  2.8262e-01],\n",
       "         [ 6.5701e-01, -3.2787e-01,  2.4968e-01,  ..., -2.5919e-01,\n",
       "           2.0175e-01,  3.3275e-01],\n",
       "         [ 2.0160e-01,  1.5783e-01,  9.8973e-03,  ..., -3.8850e-01,\n",
       "           4.1307e-01,  3.9732e-01],\n",
       "         [ 1.0175e+00,  6.4387e-01, -7.8147e-01,  ..., -4.2109e-01,\n",
       "           1.0925e+00, -4.8456e-02]]], grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.6856,  0.5262,  1.0000,  ...,  1.0000, -0.6112,  0.9971],\n",
       "        [-0.6055,  0.4997,  0.9998,  ...,  0.9999, -0.6753,  0.9769],\n",
       "        [-0.7702,  0.5447,  0.9999,  ...,  1.0000, -0.4655,  0.9894]],\n",
       "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c669d18c",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "https://huggingface.co/learn/nlp-course/chapter2/2?fw=pt\n",
    "\n",
    "https://huggingface.co/learn/nlp-course/chapter2/3?fw=pt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
